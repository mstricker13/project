X_IuUY%_JuUY%_Y%_T_1_2_3_4

X: Type of Recurrent architecture e.g. LSTM or GRU
I: Number of layers in encoder
J: Number of layers in decoder
U: units used
Y: Marks if dropout is applied. Is not existent or D if it was applied. If it is after I or J, then dropout was also applied in the respective layers
%: Dropoutrate, given without the 0. before it. E.g. D5 means dropout rate of 0.5
T: Using Theta predictions as teacher enforcing alternative. T stands there if using else it is not there

the last 4 values are always there. They represent:
1: the horizon
2: the window size
3: the step size
4: the sequence ID the network was trained on